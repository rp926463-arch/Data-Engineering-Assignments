{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.6"},"colab":{"name":"fresher-data-engineer_firstname_lastname.ipynb","provenance":[],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"-x5KVXC4scPv"},"source":["FRESHER - DATA ENGINEER"]},{"cell_type":"markdown","metadata":{"id":"0VAs33LescP2"},"source":["This test consits of fifteen problems divided among five separated sections. You are required to write your code in cell below each problem and output the result in cell next to it "]},{"cell_type":"markdown","metadata":{"id":"dOODaafpscP3"},"source":["**Total Time**: 3 hours <br>\n","**Maximum Marks**: 100"]},{"cell_type":"markdown","source":["**STACK CHOICE**<br>\n","You can choose to code in either of the two stacks below\n","\n"],"metadata":{"id":"M8cbjalyhT-4"}},{"cell_type":"markdown","source":["**STACK A**: Python3"],"metadata":{"id":"2qtogMMohiP8"}},{"cell_type":"markdown","source":["**NOTE 1**: You must code in Python3 <br>\n","**NOTE 2**: You should code in functional programming paradigm (lamda, map, reduce, filter etc). This is not mandatory, however, highly desired <br>\n","**NOTE 3**: You must keep path, paramaters & variables as dynamic (don't hardcode them) <br>\n","**NOTE 4**: You can use 'for loops' or any loop whatsoever, however, it would be desired if you can avoid them <br>\n","**NOTE 5**: You can remove code statements related to PySpark3, if happen to choose this stack for coding"],"metadata":{"id":"BaUnmZYrh_25"}},{"cell_type":"markdown","source":["**------------------------------------------------------------------------------ OR ------------------------------------------------------------------------------**"],"metadata":{"id":"rcJ_CvG-itRO"}},{"cell_type":"markdown","source":["**STACK B**: PySpark3"],"metadata":{"id":"WukJ_A0EhYYv"}},{"cell_type":"markdown","metadata":{"id":"LiGYw_q0scP3"},"source":["**NOTE 1**: You must code in PySpark3 <br>\n","**NOTE 2**: You must code in functional programming paradigm (lamda, map, reduce, filter etc) <br>\n","**NOTE 3**: You must keep path, paramaters & variables as dynamic (don't hardcode them) <br>\n","**NOTE 4**: You strictly can't use 'for loops' or any loop whatsoever"]},{"cell_type":"markdown","metadata":{"id":"WCqPOAdWscP4"},"source":["Rename and Save the notebook as fresher-data-engineer_firstname-lastname (eg. fresher-data-engineer_sahil-gupta.ipynb)"]},{"cell_type":"markdown","metadata":{"id":"CNz-9PxIscP5"},"source":["Your FullName: <br>\n","Your Email: <br>\n","Your Mobile No:"]},{"cell_type":"markdown","metadata":{"id":"d5A0Lpj_scP5"},"source":["********************************************* Test starts here **************************************************"]},{"cell_type":"markdown","metadata":{"id":"9JDFYWyDscP5"},"source":["**DATASETS**:\n","\n","1. folder 'sales' *(consists of eight CSVs corresponding to sales database)*\n","2. orchestra.json\n","3. orchestra.xml\n","4. sms.txt"]},{"cell_type":"markdown","metadata":{"id":"KOXA0balscP6"},"source":["**INSTRUCTIONS**:\n","\n","1. You are required to download and import datasets mentioned above\n","2. You would need to understand business involved behind sales database tables (eight). This is important!\n","3. Either your code should output something or leave the original comment \"#pyspark3 code here\" AS IT IS. We shall use 'Run All' in notebook and it shouldn't result an error\n","4. Test the entire notebook before uploading to Google Form provided\n","5. You can use any library in Python3/PySpark3 (untill unless prohibited to use for a paticular problem)\n","6. Output fieldname to be displayed are marked as single quotes ' ' in problem statement. You should use same field alias names whereever required\n","7. Notation for dataframe and/or array must be local to a problem's solution. Eg. Dataframe \"test\" for problem 8 should be df_prb8_test"]},{"cell_type":"code","metadata":{"id":"iuYjjiZmzcMz","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1639312329467,"user_tz":-330,"elapsed":3679,"user":{"displayName":"Busigence Careers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805263613935437233"}},"outputId":"9ffe0d4e-5870-4e51-b090-9e1c36bd7834"},"source":["#pyspark installation command - uncomment, install and comment back\n","!pip install pyspark"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: pyspark in /usr/local/lib/python3.7/dist-packages (3.2.0)\n","Requirement already satisfied: py4j==0.10.9.2 in /usr/local/lib/python3.7/dist-packages (from pyspark) (0.10.9.2)\n"]}]},{"cell_type":"code","metadata":{"id":"JcuuflXQRUb8"},"source":["#intall remaining required libraries - uncomment, install and comment back\n","#!pip install sklearn"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Zpo3R0kJscP8"},"source":["import numpy as np\n","import pandas as pd\n","import sklearn\n","#import remaining libraries here"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ClvtMDAg7Kr1"},"source":["import pyspark\n","from pyspark.context import SparkContext"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"M2yEB8L0MA4d"},"source":["#comment for first run\n","sc.stop()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ICqI0kWA6Sig"},"source":["#you can modify configuration values\n","conf = pyspark.SparkConf().setAppName(\"App\")\n","conf = (\n","         conf.setMaster('local')\n","        .set('spark.driver.memory', '8G')\n","        .set('spark.driver.cores', '8')\n","        .set('spark.python.worker.memory', '4G')\n","        .set('spark.worker.cores', '2')\n","        .set('spark.workerEnv.SPARK_WORKER_INSTANCES', '4')\n","        .set('spark.executor.instances', '8')\n","       )\n","\n","sc = pyspark.SparkContext(conf=conf)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vus4Qa__scP-"},"source":["#import CSVs (eight) here \n","#import JSONs (one) here\n","#import XMLs (one) here\n","#import TXT (one) here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"O62-2CeQscP-"},"source":["**SCORING**:\n","\n","This assessment is broadly divided into five sections A,B,C,D & E. All sections are mandatory\n","\n","**Section A**: 30 marks <br>\n","**Section B**: 15 marks <br>\n","**Section C**: 15 marks <br>\n","**Section D**: 25 marks <br>\n","**Section E**: 15 marks"]},{"cell_type":"markdown","metadata":{"id":"77P24RdzscP_"},"source":["************************************************ SECTION: A begins *******************************************"]},{"cell_type":"markdown","metadata":{"id":"8pkGLXYNscP_"},"source":["Refer & Use sales database tables (eight CSVs) to answer problem 1-5 below. <br> You cannot use any library that allows you to query pandas/pyspark DataFrames using SQL syntax. This means you would need to write code in python/pyspark, not SQL"]},{"cell_type":"markdown","metadata":{"id":"H_JI60i5scQA"},"source":["**PROBLEM 1**: Fetch the product(s) - with product description consisting of \"Universal fit, well-vented\" and meet the condition c1\n","\n","------\n","condition c1 - product had been ordered more than five times within a month \"continously\" over months\n","\n","continously means \"month after month\" this condition c1 had been met\n","\n","Eg. IF (in jan 2016 that particular product had been ordered more than five times, in feb 2016 too, in mar 2016 too, however, in apr 2016 this product had not been ordered more than five times, no matter again in may 2016 it had been again ordered more than five times) --- condition c1 stands failed "]},{"cell_type":"code","metadata":{"id":"0D1TfefGscQA"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"-f1bPomVscQB"},"source":["**PROBLEM 2**: Fetch total orders made by married male customers belonging to Central America occupied in a clerical job"]},{"cell_type":"code","metadata":{"id":"zSoOj63escQB"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uZQxb5dGscQC"},"source":["**PROBLEM 3**: List customers who ordered same product more than once in a month "]},{"cell_type":"code","metadata":{"id":"1aejdSQxscQC"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eNtpSDPZscQC"},"source":["**PROBLEM 4**: Supose Today is May 23, 2016. Display month-to-date count of returned orders <br>\n","NOTE: Month-to-date is a period starting at the beginning of the current month and ending at the current date. If today's date is May 23, 2016, then month-to-date shall be period between inclusive of May 01,2016 and May 23,2016"]},{"cell_type":"code","metadata":{"id":"pLNa3WiWscQC"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lfX-WYlLscQD"},"source":["**PROBLEM 5**: Fetch the top selling model and it's sale value, for each subcategory"]},{"cell_type":"code","metadata":{"id":"DAba-Qo-scQD"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pbFs5ZU3scQD"},"source":["************************************************ SECTION: A ends *******************************************"]},{"cell_type":"markdown","metadata":{"id":"XVuZkRTcscQE"},"source":["Refer & Use Orchestra.json to answer problem 6-8 below"]},{"cell_type":"markdown","metadata":{"id":"wRd2HPq1scQE"},"source":["************************************************ SECTION: B starts *******************************************"]},{"cell_type":"markdown","metadata":{"id":"Tlv8DPnSscQE"},"source":["**PROBLEM 6**: Display the instrument played by Lehmann Caroline "]},{"cell_type":"code","metadata":{"id":"GjItj6azscQE"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vi3Wrk7AscQF"},"source":["**PROBLEM 7**: Display all vocalists "]},{"cell_type":"code","metadata":{"id":"fwxKJYtSscQF"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DA-j-QgrscQF"},"source":["**PROBLEM 8**: Display orchestra played under program id 2561 "]},{"cell_type":"code","metadata":{"id":"eMaPSxNZscQF"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VjbV0GiuscQG"},"source":["************************************************ SECTION: B ends *******************************************"]},{"cell_type":"markdown","metadata":{"id":"dPiWdbUNscQG"},"source":["Refer & Use Orchestra.xml to answer problem 9-10 below"]},{"cell_type":"markdown","metadata":{"id":"S5erDhrmscQG"},"source":["************************************************ SECTION: C starts *******************************************"]},{"cell_type":"markdown","metadata":{"id":"ainIvRPOscQG"},"source":["**PROBLEM 9**: Display locations used for event at time 8:15 PM "]},{"cell_type":"code","metadata":{"id":"Y8mXEG-KscQH"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"lJV0wGbSscQH"},"source":["**PROBLEM 10**: Display total number of programs "]},{"cell_type":"code","metadata":{"id":"gDPcxHqkscQH"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DEFCng54scQH"},"source":["************************************************ SECTION: C ends *******************************************"]},{"cell_type":"markdown","metadata":{"id":"KaC38EliscQI"},"source":["Refer sales database tables (eight CSVs from section A) and sms.txt"]},{"cell_type":"markdown","metadata":{"id":"_mzGUGFjscQI"},"source":["************************************************ SECTION: D starts *******************************************"]},{"cell_type":"markdown","metadata":{"id":"qYwIaE8HscQI"},"source":["**PROBLEM 11**: Study article https://en.wikipedia.org/wiki/Davies–Bouldin_index \n","\n","Write code to create five unsupervised clusters for customers (table: customers), followed by calculating Davies–Bouldin index for each created cluster (you can't use in-built library for Davies–Bouldin index)"]},{"cell_type":"code","metadata":{"id":"SNiIYjtuscQJ"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"G3lB-Y-xscQJ"},"source":["**PROBLEM 12**: Prepare dataset (train-60%,validate-20%,test-20%) with customers, customers attributes and sales value (for orders placed by these customers). Use PySpark MLLib to develop a regression model to predict sales value for new customers (test-20%)"]},{"cell_type":"code","metadata":{"id":"h77mgrJAbrwY"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NzFEnh07scQJ"},"source":["**PROBLEM 13**: Fetch count of stop-words for ham & spam (compute count of stop-words for each record on worker nodes and aggregate for count ham & spam on driver node)\n","\n","---\n","Stopwords are the words in any language which does not add much meaning to a sentence. They can safely be ignored without sacrificing the meaning of the sentence"]},{"cell_type":"code","metadata":{"id":"ruaiHIFqvYfS"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hT5RFCZLscQK"},"source":["************************************************ SECTION: D ends *******************************************"]},{"cell_type":"markdown","metadata":{"id":"ys_egvZtscQK"},"source":["************************************************ SECTION: E starts *******************************************"]},{"cell_type":"markdown","metadata":{"id":"A-PGNf0-scQK"},"source":["Review JSON snippet below"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kRcqskh5scQK","executionInfo":{"status":"ok","timestamp":1639312330055,"user_tz":-330,"elapsed":33,"user":{"displayName":"Busigence Careers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805263613935437233"}},"outputId":"e7d5f50a-c905-4b1c-9716-6afac636bd95"},"source":["[\n","  {\n","    \"payee\": {\n","      \"type\": {\n","        \"location\": [\n","          {\n","            \"country\": \"usa\",\n","            \"code\": \"1\"\n","          }\n","        ]\n","      }\n","    }\n","  },\n","  {\n","    \"payee\": {\n","      \"type\": {\n","        \"location\": [\n","          {\n","            \"country\": \"india\",\n","            \"code\": \"2\"\n","          }\n","        ]\n","      }\n","    }\n","  }\n","]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'payee': {'type': {'location': [{'code': '1', 'country': 'usa'}]}}},\n"," {'payee': {'type': {'location': [{'code': '2', 'country': 'india'}]}}}]"]},"metadata":{},"execution_count":40}]},{"cell_type":"markdown","metadata":{"id":"BRDqXaL5scQL"},"source":["**PROBLEM 14**: Write a code to fetch value for field \"code\" for india"]},{"cell_type":"code","metadata":{"id":"W45aHXrMscQL"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0v-zdzn0scQL"},"source":["Review JSON snippet below"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xAbdjvQbscQM","executionInfo":{"status":"ok","timestamp":1639312330056,"user_tz":-330,"elapsed":28,"user":{"displayName":"Busigence Careers","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"02805263613935437233"}},"outputId":"1a24ef48-bf5f-4c9d-d490-d488a791d77d"},"source":["[\n","  {\n","    \"sequence\": 1,\n","    \"careTeamSequence\": [\n","      1\n","    ],\n","    \"productOrService\": {\n","      \"coding\": [\n","        {\n","          \"system\": \"http://example.org/fhir/CodeSystem/ex-visionservice\",\n","          \"code\": \"exam\"\n","        }\n","      ]\n","    },\n","    \"servicedDate\": \"2014-08-16\",\n","    \"unitPrice\": {\n","      \"value\": 80,\n","      \"currency\": \"USD\"\n","    },\n","    \"net\": {\n","      \"value\": 80,\n","      \"currency\": \"USD\"\n","    }\n","  }\n","]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[{'careTeamSequence': [1],\n","  'net': {'currency': 'USD', 'value': 80},\n","  'productOrService': {'coding': [{'code': 'exam',\n","     'system': 'http://example.org/fhir/CodeSystem/ex-visionservice'}]},\n","  'sequence': 1,\n","  'servicedDate': '2014-08-16',\n","  'unitPrice': {'currency': 'USD', 'value': 80}}]"]},"metadata":{},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"n3POzeVescQN"},"source":["**PROBLEM 15**: Write a code to update value (to a new value: 85) for field \"unitPrice\" for serviceDate 2014-08-16"]},{"cell_type":"code","metadata":{"id":"6sepzhCsscQN"},"source":["#pyspark3 code here"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"tNLbky--ch6l"},"source":["************************************************ SECTION: E ends *******************************************"]},{"cell_type":"markdown","metadata":{"id":"0CZNEQIHscQO"},"source":["********************************************* Test ends here **************************************************"]}]}